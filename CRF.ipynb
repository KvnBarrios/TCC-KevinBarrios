{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b3e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "from sklearn_crfsuite import CRF\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6abf28da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados do arquivo jsonl\n",
    "with open('final_data.jsonl', 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Converter os dados para o formato desejado\n",
    "sentences = []\n",
    "for item in data:\n",
    "    text = item['text']\n",
    "    entities = item['entities']\n",
    "    words = []\n",
    "    start_idx = 0\n",
    "    for start, end, label in entities:\n",
    "        # Adicionar palavras antes da entidade atual (se houver)\n",
    "        words.extend([(word, 'O') for word in text[start_idx:start].split()])\n",
    "        # Adicionar a entidade atual\n",
    "        words.extend([(word, label) for word in text[start:end].split()])\n",
    "        start_idx = end\n",
    "    # Adicionar palavras após a última entidade\n",
    "    words.extend([(word, 'O') for word in text[start_idx:].split()])\n",
    "    sentences.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10f20f7-adb8-4556-8a16-b1b80ab39220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções para extração de características e rótulos\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    label = sent[i][1]\n",
    "    features = {\n",
    "        'bias': '1.0',\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': str(word.isupper()),\n",
    "        'word.istitle()': str(word.istitle()),\n",
    "        'word.isdigit()': str(word.isdigit()),\n",
    "        'label': label\n",
    "    }\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3deee066-4be3-42e2-915f-c4d31e07c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bfbbd4-3ef1-4672-b54d-5f5ed7cbdc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "    return [label for word, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff25cec-5f95-41d3-b90f-f2235e1c6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separe os dados em treino e teste\n",
    "sentences_train, sentences_test = train_test_split(sentences, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f66c93d-7795-46b5-bf3f-26117b8f6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para o modelo - TREINO\n",
    "X_train = [sent2features(s) for s in sentences_train]\n",
    "y_train = [sent2labels(s) for s in sentences_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe67e7f8-fa19-40bb-83dc-901a57d1621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para o modelo - TESTE\n",
    "X_test = [sent2features(s) for s in sentences_test]\n",
    "y_test = [sent2labels(s) for s in sentences_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e84601aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do modelo CRF\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=5,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "539cad72-c84b-4390-b09b-d9041f8f0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "# Use o modelo treinado para prever as tags nas sentenças de teste\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e497475c-ccd0-4ffa-b24e-ea967f14f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Nao Risco       1.00      1.00      1.00      1173\n",
      "           O       0.00      0.00      0.00       124\n",
      "       Risco       0.69      1.00      0.81       263\n",
      "\n",
      "    accuracy                           0.92      1560\n",
      "   macro avg       0.56      0.67      0.60      1560\n",
      "weighted avg       0.87      0.92      0.89      1560\n",
      "\n",
      "Acurácia: 0.9205128205128205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Flatten (achatar) os dados\n",
    "y_true_flat = [label for sentence in y_test for label in sentence]\n",
    "y_pred_flat = [label for sentence in y_pred for label in sentence]\n",
    "\n",
    "# Calcular e imprimir as métricas\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_true_flat, y_pred_flat))\n",
    "print(\"Acurácia:\", accuracy_score(y_true_flat, y_pred_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004036f-abcd-4c5a-aea4-6986f70229d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BALANCEANDO AS CATEGORIAS - 1 - DIMINUIR OS NÃO RISCOS Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5390c6b-c50e-4572-a56b-0340c25747a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados do arquivo jsonl\n",
    "with open('final_data.jsonl', 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Converter os dados para o formato desejado\n",
    "sentences = []\n",
    "for item in data:\n",
    "    text = item['text']\n",
    "    entities = item['entities']\n",
    "    words = []\n",
    "    start_idx = 0\n",
    "    for start, end, label in entities:\n",
    "        # Adicionar palavras antes da entidade atual (se houver)\n",
    "        words.extend([(word, 'O') for word in text[start_idx:start].split()])\n",
    "        # Adicionar a entidade atual\n",
    "        words.extend([(word, label) for word in text[start:end].split()])\n",
    "        start_idx = end\n",
    "    # Adicionar palavras após a última entidade\n",
    "    words.extend([(word, 'O') for word in text[start_idx:].split()])\n",
    "    sentences.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc1dd6ef-4d63-4456-974e-6ad077c43453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Contando o número de sentenças de cada classe\n",
    "risco_sentences = [s for s in sentences if any(label == 'Risco' for word, label in s)]\n",
    "nao_risco_sentences = [s for s in sentences if all(label == 'Nao Risco' for word, label in s)]\n",
    "\n",
    "# Realizando o undersampling\n",
    "min_count = min(len(risco_sentences), len(nao_risco_sentences))\n",
    "risco_sentences = random.sample(risco_sentences, min_count)\n",
    "nao_risco_sentences = random.sample(nao_risco_sentences, min_count)\n",
    "\n",
    "# Combinando as sentenças novamente\n",
    "balanced_sentences = risco_sentences + nao_risco_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52d8af8d-8143-4754-a7c1-e20a934ecabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test = train_test_split(balanced_sentences, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae2ff3c2-e27f-45d0-a5da-ece7c998b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para o modelo - TREINO\n",
    "X_train = [sent2features(s) for s in sentences_train]\n",
    "y_train = [sent2labels(s) for s in sentences_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b161650-987f-46ed-a0f4-c85efdc9f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para o modelo - TESTE\n",
    "X_test = [sent2features(s) for s in sentences_test]\n",
    "y_test = [sent2labels(s) for s in sentences_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e83da7c-fac0-4b7b-a76e-d8cc887d03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do modelo CRF\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=5,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2aa9ed16-57ed-4ea5-bf7e-3699f444b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "# Use o modelo treinado para prever as tags nas sentenças de teste\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f51c5f7-3694-4d48-affd-a3b17cc244af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Nao Risco       0.94      1.00      0.97       900\n",
      "           O       0.00      0.00      0.00       118\n",
      "       Risco       0.81      1.00      0.89       262\n",
      "\n",
      "    accuracy                           0.91      1280\n",
      "   macro avg       0.58      0.67      0.62      1280\n",
      "weighted avg       0.83      0.91      0.86      1280\n",
      "\n",
      "Acurácia: 0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Flatten (achatar) os dados\n",
    "y_true_flat = [label for sentence in y_test for label in sentence]\n",
    "y_pred_flat = [label for sentence in y_pred for label in sentence]\n",
    "\n",
    "# Calcular e imprimir as métricas\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_true_flat, y_pred_flat))\n",
    "print(\"Acurácia:\", accuracy_score(y_true_flat, y_pred_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb221a-37be-49c5-9875-a52668c6bded",
   "metadata": {},
   "source": [
    "# BALANCEANDO AS CATEGORIAS - 2 - AUMENTAR OS RISCOS Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "32d086e7-17cc-48dc-8ba5-d969a1bd1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Separe as sentenças em risco e não risco\n",
    "risco_sentences = [s for s in sentences if any(label == 'Risco' for word, label in s)]\n",
    "nao_risco_sentences = [s for s in sentences if all(label == 'Nao Risco' for word, label in s)]\n",
    "\n",
    "# Verifique qual categoria tem menos sentenças\n",
    "minority_class = min(len(risco_sentences), len(nao_risco_sentences))\n",
    "\n",
    "# Realize o oversampling para a classe minoritária\n",
    "if len(risco_sentences) < len(nao_risco_sentences):\n",
    "    risco_sentences += random.choices(risco_sentences, k=len(nao_risco_sentences) - len(risco_sentences))\n",
    "else:\n",
    "    nao_risco_sentences += random.choices(nao_risco_sentences, k=len(risco_sentences) - len(nao_risco_sentences))\n",
    "\n",
    "# Combine as listas e misture-as\n",
    "balanced_sentences = risco_sentences + nao_risco_sentences\n",
    "random.shuffle(balanced_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "127b2dd1-3a87-459a-b9d5-cb39bd706509",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'balanced_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sentences_train, sentences_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mbalanced_sentences\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'balanced_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "sentences_train, sentences_test = train_test_split(balanced_sentences, test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ee62a387-4225-4fca-bbba-f3214dd27227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para o modelo - TREINO\n",
    "X_train = [sent2features(s) for s in sentences_train]\n",
    "y_train = [sent2labels(s) for s in sentences_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5ae24cfb-38b6-414d-a5d6-0a59da59a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para o modelo - TESTE\n",
    "X_test = [sent2features(s) for s in sentences_test]\n",
    "y_test = [sent2labels(s) for s in sentences_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ff28f01d-0085-4f39-804d-1e7de88b9bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do modelo CRF\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=5,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2953ca5e-7b03-41ab-a90d-fe58a834bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "# Use o modelo treinado para prever as tags nas sentenças de teste\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "adac4e18-b0be-48d6-acc0-71dc870f0fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Nao Risco       0.93      1.00      0.96      1248\n",
      "           O       0.00      0.00      0.00       153\n",
      "       Risco       0.87      1.00      0.93       359\n",
      "\n",
      "    accuracy                           0.91      1760\n",
      "   macro avg       0.60      0.67      0.63      1760\n",
      "weighted avg       0.83      0.91      0.87      1760\n",
      "\n",
      "Acurácia: 0.9130681818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Flatten (achatar) os dados\n",
    "y_true_flat = [label for sentence in y_test for label in sentence]\n",
    "y_pred_flat = [label for sentence in y_pred for label in sentence]\n",
    "\n",
    "# Calcular e imprimir as métricas\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_true_flat, y_pred_flat))\n",
    "print(\"Acurácia:\", accuracy_score(y_true_flat, y_pred_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee890c-03b5-4cd2-a7c0-9d5bda87da9f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BALANCEANDO AS CATEGORIAS - FINAL - Oversampling e Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04ee63db-50ba-4063-b617-6a0961366e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes do balanceamento - Risco: 55, Não Risco: 133\n",
      "Após o balanceamento - Risco: 133, Não Risco: 133\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Separe as sentenças em risco e não risco\n",
    "risco_sentences = [s for s in sentences if any(label == 'Risco' for word, label in s)]\n",
    "nao_risco_sentences = [s for s in sentences if all(label != 'Não Risco' for word, label in s)]\n",
    "\n",
    "# Imprima o número de sentenças antes do balanceamento\n",
    "print(f'Antes do balanceamento - Risco: {len(risco_sentences)}, Não Risco: {len(nao_risco_sentences)}')\n",
    "\n",
    "# Determine o número mínimo de exemplos entre as categorias e garanta que seja pelo menos tão grande quanto o tamanho original da classe minoritária\n",
    "original_min_examples = min(len(risco_sentences), len(nao_risco_sentences))\n",
    "min_examples = max(original_min_examples, len(risco_sentences), len(nao_risco_sentences))  # ajustado aqui\n",
    "\n",
    "# Realize o undersampling ou oversampling para igualar o número mínimo de exemplos\n",
    "risco_sentences = random.sample(risco_sentences, min_examples) if len(risco_sentences) > min_examples else random.choices(risco_sentences, k=min_examples - len(risco_sentences)) + risco_sentences\n",
    "nao_risco_sentences = random.sample(nao_risco_sentences, min_examples) if len(nao_risco_sentences) > min_examples else random.choices(nao_risco_sentences, k=min_examples - len(nao_risco_sentences)) + nao_risco_sentences\n",
    "\n",
    "# Imprima o número de sentenças após o balanceamento\n",
    "print(f'Após o balanceamento - Risco: {len(risco_sentences)}, Não Risco: {len(nao_risco_sentences)}')\n",
    "\n",
    "# Combine as listas e misture-as\n",
    "balanced_sentences = risco_sentences + nao_risco_sentences\n",
    "random.shuffle(balanced_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0679948-9dfb-4f0e-bf05-778a889004fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test = train_test_split(balanced_sentences, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e36e4c6-267f-44d0-ae5e-0b031cc7e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para o modelo - TREINO\n",
    "X_train = [sent2features(s) for s in sentences_train]\n",
    "y_train = [sent2labels(s) for s in sentences_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc95aece-0fee-4f6f-aa56-ead2b19009f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para o modelo - TESTE\n",
    "X_test = [sent2features(s) for s in sentences_test]\n",
    "y_test = [sent2labels(s) for s in sentences_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2ba5e37-2a52-48f1-bccc-3310c1d3664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do modelo CRF\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=5,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "211073b6-ad3f-4642-85df-f8227c8790fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "# Use o modelo treinado para prever as tags nas sentenças de teste\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6abc2b3-f389-4374-9f7f-d5e6d47ffc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Nao Risco       0.95      1.00      0.98      1955\n",
      "           O       0.00      0.00      0.00       337\n",
      "       Risco       0.78      1.00      0.88       840\n",
      "\n",
      "    accuracy                           0.89      3132\n",
      "   macro avg       0.58      0.67      0.62      3132\n",
      "weighted avg       0.80      0.89      0.84      3132\n",
      "\n",
      "Acurácia: 0.8924010217113666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Flatten (achatar) os dados\n",
    "y_true_flat = [label for sentence in y_test for label in sentence]\n",
    "y_pred_flat = [label for sentence in y_pred for label in sentence]\n",
    "\n",
    "# Calcular e imprimir as métricas\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_true_flat, y_pred_flat))\n",
    "print(\"Acurácia:\", accuracy_score(y_true_flat, y_pred_flat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baacc58-864b-4797-a589-ef7cba68ac20",
   "metadata": {},
   "source": [
    "# Terceiro experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "681efe8c-edaf-4406-a39b-585e6048f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados do arquivo jsonl\n",
    "with open('admin.jsonl', 'r', encoding='utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Converter os dados para o formato desejado\n",
    "sentences = []\n",
    "for item in data:\n",
    "    text = item['text']\n",
    "    entities = item['entities']\n",
    "    words = []\n",
    "    start_idx = 0\n",
    "    for start, end, label in entities:\n",
    "        # Adicionar palavras antes da entidade atual (se houver)\n",
    "        words.extend([(word, 'O') for word in text[start_idx:start].split()])\n",
    "        # Adicionar a entidade atual\n",
    "        words.extend([(word, label) for word in text[start:end].split()])\n",
    "        start_idx = end\n",
    "    # Adicionar palavras após a última entidade\n",
    "    words.extend([(word, 'O') for word in text[start_idx:].split()])\n",
    "    sentences.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d73249af-78fc-4524-8a61-1a65e3727a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# Separate sentences by category\n",
    "nao_risco_sentences = [s for s in sentences if all(label == 'Nao Risco' for word, label in s)]\n",
    "risco_ambiental_sentences = [s for s in sentences if any(label == 'Risco ambiental' for word, label in s)]\n",
    "risco_saude_sentences = [s for s in sentences if any(label == 'Risco de saude' for word, label in s)]\n",
    "risco_financeiro_sentences = [s for s in sentences if any(label == 'Risco financeiro' for word, label in s)]\n",
    "risco_legal_sentences = [s for s in sentences if any(label == 'Risco legal' for word, label in s)]\n",
    "\n",
    "# Determine the size of the largest class\n",
    "majority_class_size = len(nao_risco_sentences)\n",
    "\n",
    "# Perform oversampling for each minority class\n",
    "categories = [risco_ambiental_sentences, risco_saude_sentences, risco_financeiro_sentences, risco_legal_sentences]\n",
    "for category in categories:\n",
    "    category += random.choices(category, k=majority_class_size - len(category))\n",
    "\n",
    "# Combine all categories\n",
    "balanced_sentences = nao_risco_sentences\n",
    "for category in categories:\n",
    "    balanced_sentences += category\n",
    "\n",
    "# Shuffle the combined list\n",
    "random.shuffle(balanced_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8ae95fdb-0688-4460-a690-b88808dd2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_set, test_set = train_test_split(balanced_sentences, test_size=0.20, random_state=42)\n",
    "train_set, val_set = train_test_split(train_val_set, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "13836adc-59e4-409e-87e6-98dc0b7ceace",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in train_set]\n",
    "y_train = [sent2labels(s) for s in train_set]\n",
    "X_val = [sent2features(s) for s in val_set]\n",
    "y_val = [sent2labels(s) for s in val_set]\n",
    "X_test = [sent2features(s) for s in test_set]\n",
    "y_test = [sent2labels(s) for s in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1103547d-d7c1-4f5d-a055-9ea9640dd097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do modelo CRF\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=5,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5e800c1a-d3ba-45ad-a0df-23e2b2ae62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "# Use o modelo treinado para prever as tags nas sentenças de teste\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "cae84923-8a77-47b8-abd7-1b8edcc43f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       Nao Risco       0.82      1.00      0.90       737\n",
      " Risco ambiental       0.00      0.00      0.00       100\n",
      "  Risco de saude       1.00      1.00      1.00       145\n",
      "Risco financeiro       1.00      1.00      1.00        91\n",
      "     Risco legal       1.00      0.32      0.49        93\n",
      "\n",
      "        accuracy                           0.86      1166\n",
      "       macro avg       0.76      0.66      0.68      1166\n",
      "    weighted avg       0.80      0.86      0.81      1166\n",
      "\n",
      "Acurácia: 0.8602058319039451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kevin\\PycharmProjects\\ModeloCRF\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Flatten (achatar) os dados\n",
    "y_true_flat = [label for sentence in y_test for label in sentence]\n",
    "y_pred_flat = [label for sentence in y_pred for label in sentence]\n",
    "\n",
    "# Calcular e imprimir as métricas\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_true_flat, y_pred_flat))\n",
    "print(\"Acurácia:\", accuracy_score(y_true_flat, y_pred_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c1528-8c37-45e7-97ca-698a5813a176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
